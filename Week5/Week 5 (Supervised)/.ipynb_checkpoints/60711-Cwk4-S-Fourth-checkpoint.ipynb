{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# COMP60711 - Part 2 Coursework 2\n",
    "\n",
    "|                           |                                                                                                                                                                               |\n",
    "|--------------------------:|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "|              Course Unit: | COMP60711: Data Engineering                                                                                                                                                   |\n",
    "| Responsible Staff Member: | Professor John Keane                                                                                                                                                          |\n",
    "|                    Marks: | This coursework is worth **25%** of the overall marks for this unit.                                                                                                                |\n",
    "|              Submissions: | This is the **4th** of **4** assessed submissions.                                                                                                                                    |\n",
    "|     Method of Submitting: | This notebook, after completion, should be saved as a HTML document and submitted using Blackboard                                                                                      |\n",
    "|                 Deadline: | Thursday 31st October 10AM (UK time)                                                                                                                                                                            |\n",
    "|         Late Submissions: | Extensions will only be granted as a result of formally processed [Mitigating Circumstances](http://documents.manchester.ac.uk/DocuInfo.aspx?DocID=427). Marks for late submissions will be reduced in line with the [University policy](http://documents.manchester.ac.uk/display.aspx?DocID=24561). |\n",
    "\n",
    "Please complete the questions in the spaces provided (under the \"Answer\" block for each question), then download the notebook in HTML format and submit to Blackboard.\n",
    "\n",
    "Please also add your student ID and name below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "| Student ID (7-8 digit number) | Full Name |\n",
    "|:-------------------------------:|:-----------:|\n",
    "|       12345678                 |  Name Here         |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reminders\n",
    "* **Please make clear any assumptions and provide evidence to justify your answers** \n",
    "* Jupyter notebooks use markdown. A brief summary of how to use markdown can be seen [here](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet). Otherwise, please refer to the brief guide on Blackboard.\n",
    "* You **must** cite any sources used, from web pages to academic papers and textbooks.\n",
    "* Please ensure your code has no errors, and that the output is shown in your submitted version.\n",
    "* We have added some general notebooks on Blackboard to cover the basics of plotting in Python, Jupyter notebooks, and anaconda.\n",
    "* Some questions require a mixture of code and text to answer the question. Marks are awarded based on the output of your code (i.e. graphs) and the explanation provided, not on the code itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Q1: Pre-processing & Feature Importance (9 marks)\n",
    "\n",
    "This question will use the `\"genes-leukemia.csv\"` dataset available on Blackboard. For some background information about this dataset, see https://www.kdnuggets.com/data_mining_course/data/genes-leukemia-description.txt. The sub-questions will involve inspecting and pre-processing the data in order to use a decision tree. We will then look at which features are deemed important for prediction, and how removing important features affects tree structure.\n",
    "\n",
    "It is expected that you will use `pandas` for this question, though this is not a requirement (but it may be more difficult if you do not).\n",
    "\n",
    "## Q1.1 (1 mark)\n",
    "\n",
    "Count the number of records/examples where the \"Treatment_Response\" feature is non-missing. Describe these examples in terms of the other features (Year from XXXX to YYYY, Gender = X etc.)\n",
    "\n",
    "**Hint:**\n",
    "* You need to ensure that you are looking at all of the data. By default, some of the columns may be truncated, in which case you should adjust this (through e.g. `pd.set_option(\"display.max_columns\", 100)`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.1 Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Q1.2 (1 mark)\n",
    "\n",
    "Explain why it is not correct to build predictive models for \"Treatment_Response\" using records where it is missing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.2 Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "### From Q1.3-Q1.6 (inclusive), use only the subset of data where \"Treatment_Response\" is non-missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Q1.3 (1 mark)\n",
    "\n",
    "Remove the features that are either all the same or have all missing values. Which sample fields should you keep?\n",
    "\n",
    "**Hints:**\n",
    "* For simplicity in the following questions, also remove \"FAB_if_AML\".\n",
    "* \"SNUM\" should be the index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.3 Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Q1.4 (1 mark)\n",
    "\n",
    "Fit a decision tree (`DecisionTreeClassifier`) using default settings to the data, now that it has been pre-processed.\n",
    "\n",
    "As we have a small amount of data, if we want to more meaningfully assess the performance, we should use leave-one-out cross-validation. Report the accuracy across each fold, and the overall mean accuracy obtained.\n",
    "\n",
    "Important: Please use `random_state=42` where necessary to ensure reproducible results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.4 Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Q1.5 (3 marks)\n",
    "\n",
    "Split the data into a training and test set (using a 75:25 ratio). Once again, fit a decision tree to this data, and report the accuracy. Visualize the tree (using `tree.plot_tree`), and state which feature/predictor is the most important. Then, removing this top predictor, fit the tree again with this feature removed. Again, report the accuracy and visualize the tree.\n",
    "\n",
    "Compare the accuracy between the two trees. Explain why the tree is different with this feature removed.\n",
    "\n",
    "Important: Please use `random_state=3` where necessary to ensure reproducible results.\n",
    "\n",
    "**Hint:**\n",
    "* You need to ensure that the _original_ feature names are visible in the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.5 Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Q1.6 (2 marks)\n",
    "\n",
    "Which tree do you think is more generalizable? You may want to more thoroughly compare the trees (readability, sensitivity/specificity, structure simplicity, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.6 Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Q2: Decision Boundaries (4 marks)\n",
    "\n",
    "In this question, we will visualize the decision boundaries formed by three simple classifiers on an example dataset.\n",
    "\n",
    "## Q2.1 (4 marks)\n",
    "\n",
    "We have provided code below to produce the data and to create the decision boundary. You will need to run this code using the following models:\n",
    "1. \"ZeroR\" classifier - `sklearn.dummy.DummyClassifier` using the `\"most_frequent\"` strategy.\n",
    "2. KNN classifier - `sklearn.neighbors.KNeighborsClassifier`\n",
    "3. Decision tree classifier - `sklearn.tree.DecisionTreeClassifier`\n",
    "\n",
    "You will need to modify the code to output the accuracy for each of the models. Using both this information and the visualized decision boundaries, explain the performance of these algorithms. A brief explanation of the classifiers will be required for this.\n",
    "\n",
    "**Hints:**\n",
    "* Although not necessary, the use of further visualizations, performance measures, or even datasets may help to support your discussion\n",
    "* Use the decision boundaries as a reference point to explain the **differences** between the classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The code below provides you with the functions to get the data,\n",
    "and plot the decision boundary.\n",
    "\n",
    "The resulting graphs have not been properly formatted, however,\n",
    "so you will need to add that. You will also need to modify the \n",
    "code to output the accuracy.\n",
    "'''\n",
    "\n",
    "import numpy as np    \n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "def get_data():\n",
    "    # Create data\n",
    "    data, labels = make_classification(\n",
    "        n_features=2, n_redundant=0, n_informative=2,\n",
    "        random_state=1, n_clusters_per_class=1\n",
    "    )\n",
    "    # Set the RNG\n",
    "    rng = np.random.RandomState(42)\n",
    "    # Add some noise\n",
    "    data += 2 * rng.uniform(size=data.shape)\n",
    "    return data, labels\n",
    "\n",
    "def plot_boundary(X, ax, clf):\n",
    "    # Plotting decision regions\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(\n",
    "        np.arange(x_min, x_max, 0.1),\n",
    "        np.arange(y_min, y_max, 0.1)\n",
    "    )\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    ax.contourf(xx, yy, Z, alpha=0.4)\n",
    "    return ax\n",
    "    \n",
    "def boundary_full(data, labels, model, name, **kwargs):\n",
    "    # Create estimator/model/classifier\n",
    "    clf = model(**kwargs)\n",
    "    # Fit the classifier\n",
    "    clf.fit(data, labels)\n",
    "\n",
    "    # Create axis\n",
    "    fig, ax = plt.subplots()\n",
    "    # Call the provided function\n",
    "    ax = plot_boundary(data, ax, clf)\n",
    "    # Now add the data (using scatter)\n",
    "    # Ensure to colour the points according to the prediction\n",
    "    ax.scatter(data[:,0], data[:,1], c=labels, s=20, edgecolor=\"k\")\n",
    "    # Format the graph...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2.1 Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Question 3: Training Time Comparison (4 marks)\n",
    "\n",
    "## Q3.1 (2 marks)\n",
    "\n",
    "Plot the training time for both `DecisionTreeClassifier` and `GaussianNB` against the data size. A function to generate the data is provided to you, which takes the size as its only argument.\n",
    "\n",
    "Explain what you observe and your understanding in terms of training time and data size (include a graph). Consider algorithm implementation and potential stochasticity in running times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this function to measure the time\n",
    "from time import time\n",
    "\n",
    "# Use this function to generate the data\n",
    "def create_data(size):\n",
    "    # Create data\n",
    "    data, labels = make_classification(\n",
    "        n_samples=size,\n",
    "        n_features=2, n_redundant=0, n_informative=2,\n",
    "        random_state=4, n_clusters_per_class=1\n",
    "    )\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3.1 Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Q3.2 (2 marks)\n",
    "What do you think would happen if we continue increasing the number of instances? Which of the algorithms would be more suitable for a very large number of instances and why? Consider the algorithmsâ€™ complexity and how they scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3.2 Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Question 4: Memory Usage Comparison (3 marks)\n",
    "\n",
    "# Q4.1 (3 marks)\n",
    "\n",
    "Plot the memory usage of the `DecisionTree` model against the data size. Explain the memory usage of the model (including a graph in your answer).\n",
    "\n",
    "You should use the same `create_data()` function provided for Q3, and ensure that you have downloaded `memory.py` from Blackboard in order to load the `measure_memory()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memory import measure_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4.1 Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
